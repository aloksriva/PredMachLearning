{"name":"Predmachlearning","tagline":"","body":"\r\n<body>\r\n<h1>Human Activity Recognition using Random Forest Prediction Model</h1>\r\n\r\n<h3>Data</h3>\r\n\r\n<p>This exercise is aimed at predicting the class of exercise performed by users based on data captured using wearable accelerometers.\r\nAHR dataset for this study is provided by Groupware (<a href=\"http://groupware.les.inf.puc-rio.br/har\">http://groupware.les.inf.puc-rio.br/har</a>)</p>\r\n\r\n<h3>Exploratory Analysis</h3>\r\n\r\n<p>The raw dataset not only contained the accelerometers measurements but also computed statistics (Variance, Standard Devation, skewness, Kurtosis, Max, Min, Average) for each of the observation.</p>\r\n\r\n<p>For the purpose of this analysis, we remove all columns containing computed statistics from the dataset to ensure we have correct set of mathematically independant predictors.</p>\r\n\r\n<p>Outcome variable, classe, is a factor with 5 outcomes therefore, for creating the model, we need to use Random Forest technique (since GLM can be used only if outcome variable is a factor with only 2 outcomes).</p>\r\n\r\n<h3>Fitting the Model</h3>\r\n\r\n<p>We randomly sample 3000 records from the entire training set of 19,622 records (on account of limited computational resources available for the purpose of this exercise) and fit a training model using Random Forest method on these 3000 records.</p>\r\n\r\n<p>The accuracy predicted by the model is 100% while that from Confusion Matrix is 96.7%</p>\r\n\r\n<h3>Cross Validation</h3>\r\n\r\n<p>For cross validation, the training model fitted above is used to predict the outcome (classe) for the entire dataset of 19,622 records. The predicted value of classe is compared with the actual value availale in the raw dataset. The observed prediction accuracy rate for the model fitted by us is 98.05%</p>\r\n\r\n<h3>Predicting for the Test Dataset</h3>\r\n\r\n<p>Finally, we use our fitted model on the testing dataset of 20 records, and append predicted values to the dataset.</p>\r\n\r\n<h3>Load required libraries</h3>\r\n\r\n<pre><code class=\"r\">suppressWarnings(library(caret))\r\n</code></pre>\r\n\r\n<pre><code>## Loading required package: lattice\r\n## Loading required package: ggplot2\r\n</code></pre>\r\n\r\n<h3>Download Raw Training and Testing Data</h3>\r\n\r\n<pre><code class=\"r\">setInternet2(TRUE)\r\ndownload.file(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;, \r\n    destfile = &quot;pml-training.csv&quot;)\r\n\r\ndownload.file(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;, \r\n    destfile = &quot;pml-testing.csv&quot;)\r\n</code></pre>\r\n\r\n<h3>Load data in csv files into datasets</h3>\r\n\r\n<pre><code class=\"r\">pmltraining &lt;- read.csv(&quot;pml-training.csv&quot;, header = TRUE)\r\npmltesting &lt;- read.csv(&quot;pml-testing.csv&quot;, header = TRUE)\r\n</code></pre>\r\n\r\n<h3>Remove columns containing mathematically/statistically calculated values and NAs from the training dataset</h3>\r\n\r\n<pre><code class=\"r\">pmltraining &lt;- pmltraining[, -grep(&quot;^var&quot;, colnames(pmltraining))]\r\npmltraining &lt;- pmltraining[, -grep(&quot;^avg&quot;, colnames(pmltraining))]\r\npmltraining &lt;- pmltraining[, -grep(&quot;^stddev&quot;, colnames(pmltraining))]\r\npmltraining &lt;- pmltraining[, -grep(&quot;^skew&quot;, colnames(pmltraining))]\r\npmltraining &lt;- pmltraining[, -grep(&quot;^kurtosis&quot;, colnames(pmltraining))]\r\npmltraining &lt;- pmltraining[, -grep(&quot;^max&quot;, colnames(pmltraining))]\r\npmltraining &lt;- pmltraining[, -grep(&quot;^min&quot;, colnames(pmltraining))]\r\n# Remove columns with NAs\r\npmltraining &lt;- pmltraining[sapply(pmltraining, function(x) !any(is.na(x)))]\r\n# Remove columns with blank values\r\npmltraining &lt;- pmltraining[, -grep(&quot;^amplitude&quot;, colnames(pmltraining))]\r\n# Remove first 5 columns since they don&#39;t contribute to effect\r\npmltraining &lt;- pmltraining[, -c(1:5)]\r\n</code></pre>\r\n\r\n<h3>Remove columns containing mathematically/statistically calculated values and NAs from the testing dataset</h3>\r\n\r\n<pre><code class=\"r\">pmltesting &lt;- pmltesting[, -grep(&quot;^var&quot;, colnames(pmltesting))]\r\npmltesting &lt;- pmltesting[, -grep(&quot;^avg&quot;, colnames(pmltesting))]\r\npmltesting &lt;- pmltesting[, -grep(&quot;^stddev&quot;, colnames(pmltesting))]\r\npmltesting &lt;- pmltesting[, -grep(&quot;^skew&quot;, colnames(pmltesting))]\r\npmltesting &lt;- pmltesting[, -grep(&quot;^kurtosis&quot;, colnames(pmltesting))]\r\npmltesting &lt;- pmltesting[, -grep(&quot;^max&quot;, colnames(pmltesting))]\r\npmltesting &lt;- pmltesting[, -grep(&quot;^min&quot;, colnames(pmltesting))]\r\n# Remove columns with NAs\r\npmltesting &lt;- pmltesting[sapply(pmltesting, function(x) !any(is.na(x)))]\r\n# Remove first 5 columns since they don&#39;t contribute to effect\r\npmltesting &lt;- pmltesting[, -c(1:5)]\r\n</code></pre>\r\n\r\n<h3>Randomly sample 3000 records from raw training dataset to match the available computing power/resources</h3>\r\n\r\n<pre><code class=\"r\">set.seed(1234)\r\ntrainInds &lt;- sample(nrow(pmltraining), 3000)\r\ntrain &lt;- data.frame(pmltraining[trainInds, ])\r\n</code></pre>\r\n\r\n<h3>Fit the training model and validate its accuracy level</h3>\r\n\r\n<pre><code class=\"r\">fitMod &lt;- suppressWarnings(train(classe ~ ., data = train, method = &quot;rf&quot;))\r\n</code></pre>\r\n\r\n<pre><code>## Loading required package: randomForest\r\n## randomForest 4.6-7\r\n## Type rfNews() to see new features/changes/bug fixes.\r\n</code></pre>\r\n\r\n<pre><code class=\"r\">fitMod\r\n</code></pre>\r\n\r\n<pre><code>## Random Forest \r\n## \r\n## 3000 samples\r\n##   54 predictors\r\n##    5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; \r\n## \r\n## No pre-processing\r\n## Resampling: Bootstrapped (25 reps) \r\n## \r\n## Summary of sample sizes: 3000, 3000, 3000, 3000, 3000, 3000, ... \r\n## \r\n## Resampling results across tuning parameters:\r\n## \r\n##   mtry  Accuracy  Kappa  Accuracy SD  Kappa SD\r\n##   2     1         0.9    0.008        0.01    \r\n##   30    1         1      0.007        0.009   \r\n##   50    1         0.9    0.01         0.01    \r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was mtry = 28.\r\n</code></pre>\r\n\r\n<pre><code class=\"r\">confusionMatrix(fitMod)\r\n</code></pre>\r\n\r\n<pre><code>## Bootstrapped (25 reps) Confusion Matrix \r\n## \r\n## (entries are percentages of table totals)\r\n##  \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 28.1  0.6  0.0  0.0  0.0\r\n##          B  0.0 18.1  0.7  0.1  0.2\r\n##          C  0.0  0.4 17.8  0.6  0.1\r\n##          D  0.1  0.0  0.2 15.3  0.2\r\n##          E  0.0  0.0  0.0  0.1 17.4\r\n</code></pre>\r\n\r\n<h3>Perform cross validation of model&#39;s accuracy with the original raw data</h3>\r\n\r\n<pre><code class=\"r\">predfit &lt;- predict(fitMod, pmltraining)\r\npmltraining$predRight &lt;- predfit == pmltraining$classe\r\ntable(predfit, pmltraining$classe)\r\n</code></pre>\r\n\r\n<pre><code>##        \r\n## predfit    A    B    C    D    E\r\n##       A 5570  107    0    5    0\r\n##       B    8 3626   86    4    3\r\n##       C    0   61 3327   60    1\r\n##       D    1    3    9 3129   21\r\n##       E    1    0    0   18 3582\r\n</code></pre>\r\n\r\n<h3>Predict outcome for the 20 test cases using the model fitted above and append the predicted outcome to the testing data. Save the results in a new &#39;output&#39; dataset. Create a .csv file with predictions for the testing dataset</h3>\r\n\r\n<pre><code class=\"r\">predictions &lt;- predict(fitMod, pmltesting)\r\npmltesting$predRight &lt;- predictions\r\noutput &lt;- cbind(pmltesting, predictions)\r\nwrite.table(output, &quot;Predictions.csv&quot;)\r\n</code></pre>\r\n\r\n</body>\r\n\r\n</html>\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}